---
title: "Tema 3 - Introducción a la inferencia estadística"
output:
  html_document: default
  word_document: default
---
#ESTADÍSTICA COMPUTACIONAL

##Juan M. Muñoz Pichardo - María Dolores Cubiles de la Vega

##Departamento de Estadística e I.O. Universidad de Sevilla
 
###TEMA 3. INTRODUCCIÓN A LA INFERENCIA ESTADÍSTICA. 

###Laboratorio 1. CONTRASTES PARAMÉTRICOS.###



**Fichero datos: golub.RData**

**DescripciÓn: contiene 3051 genes y 38 muestras divididas en 2 grupos (ALL y AML)**




```{r}
load(file="../datos/golub.RData")
library(TeachingDemos)
dim(golub)
str(golub)
head(golub)

str(golub.gnames)
head(golub.gnames)

str(gol.fac)
gol.fac
table(gol.fac)

```



##**Contraste para la Normalidad: SHAPIRO-WILK**
GrÁfico Q-Q plot (para el grupo ALL): estudio de normalidad para el gen 1022

```{r}
qqnorm(golub[1022, gol.fac=="ALL"])
qqline(golub[1022, gol.fac=="ALL"],col="red")

```

Vamos a comprobar si el gen 1022 para el grupo ALL sigue una distribuciÓn normal usando el test de Shapiro Wilk.

```{r}
shapiro.test(golub[1022, gol.fac=="ALL"])

```



#**CONTRASTES PARAMÉTRICOS**



##**Contraste para la media: t-test**

Usamos la información del gen 2058 de Golub et al. (1999) 

```{r}
x <- golub[2058,gol.fac=="ALL"]

shapiro.test(x)

## Implementación
mu0 <- 0; n <- 27
#Estadístico
(t.value<-sqrt(n)*(mean(x) - mu0)/sd(x))
# p-valor:2 * P(T26 <=-0.0010)
(2 * pt(-0.0010, 26))
# intervalo de confianza al 95%
mean(x)+qt(0.025,26)*sd(x)/sqrt(n)
mean(x)+qt(0.975,26)*sd(x)/sqrt(n)


```


Usando comando t-test (por defecto mu=0), obtenemos directamente en la salida: la estimación puntual, intervalo de confianza al 95%, el estadístico y p-valor para la resolución del contraste.


```{r}
t = t.test(x)
names(t)

#Valor del estadístico
(t$statistic)

#Intervalo de Confianza
(t$conf.int)

#Resumen de la información del contraste
t

```

Modificamos el ejemplo anterior:

1. Calculamos el intervalo de confianza a un nivel de confianza del 90%

```{r}
t.test(x,conf.level=0.9)
```

2.-  Comprobar si la media del gen se puede considerar igual a 1 con un nivel de significación del 5%.

```{r}
t.test(x,mu=1)
```

3. En caso de ser distinto comprobamos si es mayor o menor que 1.

```{r}
t.test(x,mu=1, alternative="less")

t.test(x,mu=1, alternative="greater")
```


##**Contrastes para igualdad de medias de dos muestras independientes**

Representación gráfica para comparar el gen  1042 en los dos grupos ALL y AML

```{r}
boxplot(golub[1042,]~gol.fac, col="red")
```



¿Podemos considerar iguales las medias para los dos grupos ALL y AML del gen 1042?

Primero.- Estudiamos la normalidad
```{r}
shapiro.test(golub[1042, gol.fac=="ALL"])
shapiro.test(golub[1042, gol.fac=="AML"])
```

Segundo.- Igualdad de varianzas 
```{r}
var.test(golub[1042,] ~ gol.fac)
```

Tercero.- Igualdad de medias utilizando el resultado anterior en el parámetro var.equal


```{r}
t.test(golub[1042,] ~ gol.fac, var.equal=TRUE)
# equivalente 
x = golub[1042, gol.fac=="ALL"]
y = golub[1042, gol.fac=="AML"]
t.test(x,y,var.equal=T)
```

El resultado es que ambas medias son significativamente distintas, podemos comprobar para el gen 1042 cúal tiene la media mayor o menor en los dos grupos estudiados (All y AML).

```{r}

t.test(x,y,var.equal=T,alternative="greater")

t.test(x,y,var.equal=T,alternative="less")
```




##**Contrastes para igualdad de medias de dos muestras relacionadas**

Consideramos el siguiente Problema. Se muestra la presión sanguínea sistólica medida en un conjunto de 11 individuos antes (variable X) y después (variable Y) de la administración de un hipotensor beta-bloqueante.

X : 164 144 175 196 194 205 126 165 192 148 156

Y : 144 136 152 157 147 145 142 141 109 146 148

(a) Comprobar condiciones de normalidad.

En primer lugar introducimos los datos de las dos variables (son pareadas-dependientes, deben tener el mismo número de observaciones las dos variables)

```{r}
x = c(164,144,175,196,194,205,126,165,192,148,156)
y = c(144,136,152,157,147,145,142,141,109,146,148)

```


Para trabajar con muestras dependientes, tenemos que definir la variable diferencia:

```{r}
(dif=x-y)
```


Estudiamos la Normalidad de la variable diferencia:

```{r}
shapiro.test(dif)

```


(b) Estimar con un nivel de confianza del 95% la diferencia de las presiones sistólicas medias medidas antes y después de la administración del medicamento.



Ya que podemos considerar la Normalidad de la variable diferencia, usamos la función t.test para la media de la variable diferencia igual a 0, que es equivalente a estudiar la hipótesis nula para comprobar si las dos variables tienen igual media:

```{r}
t.test(dif)
#O bien 
t.test(x,y,conf.level=.95,paired=TRUE)

#También podríamos realizar el contraste con hipótesis alternativa media X > media Y como:

t.test(x,y,alternative="greater",conf.level=.95,paired=TRUE)

```



(c) ¿Puede considerarse a un nivel de significación del 0.05 que el fármaco es efectivo para el tratamiento de la hipertensión?


**Ejercicio 3.1.**

Dos programas educativos para el uso básico del ordenador fueron aplicados a dos grupos distintos de 8 niños obteniéndose las siguientes puntuaciones:

Programa A: 77 74 82 73 87 69 66 80

Programa B: 92 98 76 68 94 88 81 76

Nota: Usar alpha= 0.05 e interpretar las conclusiones obtenidas.

(a) Comprobar normalidad en ambas distribuciones, indicar el p-valor obtenido en cada caso.

```{r}



```

(b) ¿Puede considerarse que la puntuación media de los niños a los que se les aplicó el programa A es 68? Utiliza intervalos de confianza para responder.

```{r}

```

(c) ¿Podemos suponer que ambos programas son distintos?


```{r}


```


(d) ¿Puede considerarse que el 35% de los niños a los que se aplicó el programa A obtienen puntuaciones superiores a 75?

**Contrastes para una proporción**

Para responder a esta pregunta, en primer lugar debemos considerar la variable Bernouilli que asocia exito (TRUE) a "puntuaciones superiores 75" y fracaso en caso contrario (FALSE).

```{r}
(x.bern = (x > 75))
(tabla.x.bern = table(x.bern))
```

Sobre esta variable planteamos el siguiente contraste de hipótesis sobre la probabilidad de Exito de esta variable Bernouilli.

H0 : p(E) = 0.35
H1 : p(E) != 0.35

```{r}

```

Como el p-valor obtenido es mayor que alpha no se rechaza H0, es decir, no hemos encontrado evidencias estadísticas significativas para rechazar que haya un 35% en la población con puntuaciones superiores a 75.


#**Contraste sobre la diferencia de proporciones en muestras independientes**

Consideramos el siguiente problema:

En una fábrica de piensos, se desea mejorar la conservación de los mismos, haciendo un cambio en su proceso de empaquetamiento. Se toman muestras del procedimiento de empaquetamiento existente y del nuevo para determinar si este tiene como resultado alguna mejora. Si se obtiene que 75 de 1500 sacos deteriorados con el procedimiento actual y 80 de 2000 sacos deteriorados con el procedimiento 165 nuevo, estimar la diferencia entre los porcentajes de sacos defectuosos empaquetados con el antiguo y el nuevo procedimiento a un nivel de signicación del 5 %. 

Queremos realizar el siguiente contraste de hipótesis para proporciones de dos muestras independientes:

H0 : p(X) = p(Y)
H1 : p(X) != p(Y)

Para ello nos ayudamos de la función R prop.test para dos muestras. 
Tenemos inicialmente que crear una tabla de frecuencias con los datos como podemos ver en las siguientes instrucciones:

```{r}
tabla = matrix(c(75,1500-75,80,2000-80),2,2,byrow=TRUE)
tabla
(tabla.proptest = prop.test(tabla,correct=FALSE))
```

Como el p-valor obtenido (0.1547) es mayor que 0.05 no se rechaza H0, es decir,consideramos iguales los dos procedimientos en cuanto al porcentaje de sacos defectuosos o no hemos encontrado evidencias estadísticas significativas para rechazar H0.

Podríamos utilizar también el intervalo de confianza para contestar al problema, observando que el valor 0 se encuentra dentro del intervalo (-0.00397863,0.023978634)







**Ejercicios Propuestos**

**Ejercicio 3.2**

(a) Calcular la media y mediana de los valores de los genes de expression de los pacientes de las muestras ALL, utilizar la función apply.

```{r}

```

(b) Seleccionamos el gen "CCND3 Cyclin D3" in row 1042 of golub. Representamos graficamente los dos grupos de ese gen.

```{r}

```

(c) Calculamos los cuantiles, valor máximo y mínimo para los pacientes del grupo ALL en el gen 1042.

```{r}

```



**Ejercicio 3.3.**

Obtener los nombres de los 5 genes con diferencias de medias (grupo ALL - grupo AML) más grandes.


###Laboratorio 2. CONTRASTES NO PARAMÉTRICOS.###



**Fichero datos: golub.RData**

**Descripción: contiene 3051 genes y 38 muestras divididas en 2 grupos (ALL y AML)**


```{r}
load(file="../datos/golub.RData")
library(TeachingDemos)
dim(golub)

table(gol.fac)

```


**CONTRASTES NO PARAMÉTRICOS**

**Contrastes para igualdad de medias de dos muestras independientes**

En primer lugar comprobamos la hipótesis de Normalidad
```{r}
x = golub[790, gol.fac=="ALL"]
y = golub[790, gol.fac=="AML"]

shapiro.test(x)
shapiro.test(y)

```
Si alguna de las variables no verifica la normalidad, aplicamos el test de Wilcoxon para comprobar la igualdad de las medidas

```{r}

## Wilcoxon
wilcox.test(x,y)

```
Como el p-valor obtenido es mayor que alpha, no existen evidencias significativas para rechazar la hipóteis nula, por tanto, consideramos que las medidas son iguales.

**Ejercicio 3.4.**

Comparar los genes 790 y 66 de los datos Golub para el grupo ALL.

(a) Calcular los estadísticos media, mediana, desviación típica. 

(b) Representar graficamente el diagrama de caja.

(c) Estudiar la normalidad para ambos genes.

(d) ¿Se pueden considerar iguales las medias de las expresiones de los dos genes para el grupo ALL? En caso negativo, indicar cuál es mayor o menor.




**Ejercicio 3.5.**

Realizar una función en R que para un gen determinado calcule el t-test o el test de wilcoxon dependiendo del resultado del test de Shapiro Wilk.




